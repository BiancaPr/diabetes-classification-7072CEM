{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3422e4e0-96e4-429d-a177-5ad4b387b205",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f331a6-9bb5-42b3-9225-23cc6de61e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b21640-39d4-447f-8318-d642e9349e21",
   "metadata": {},
   "source": [
    "Loading & reviewing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1d655b-6c6e-4569-b853-ec84fc31b8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset \n",
    "diabetes_df = pd.read_csv('Dataset_of_Diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07ef5ae-fdc4-4278-8712-34ecc63bc3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking dat structure\n",
    "print(diabetes_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7097e7-bdb1-44d2-8538-9773b2da3bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rechecking summary stats\n",
    "diabetes_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745313ab-5f6a-4da9-b167-31592310b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a summary of dataset, including data types and non-null counts\n",
    "print(diabetes_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd4fe2b-f758-4c48-aa70-61f54b53a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks for missing values\n",
    "print(diabetes_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecad9c2-641f-46e9-83df-20c4502b2352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks for any duplicate rows\n",
    "print(diabetes_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f2be85-d9d2-46b7-8883-c08b65622ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking class balance in the dataset\n",
    "print(diabetes_df['CLASS'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0d560f-487e-4263-a7f5-99b9d049277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning class labels to remove spaces and make all uppercase\n",
    "diabetes_df['CLASS'] = diabetes_df['CLASS'].str.strip().str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5d33a0-8bf7-4c87-ae42-c27dbc51e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualising the cleaned class distribution\n",
    "sns.countplot(x=diabetes_df['CLASS'])\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('N = Non-Diabetic - Y = Diabetic')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b00ddd7-8ab1-4ed2-b738-bd5922daa928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping irrelevant features that do not contribute to prediction\n",
    "diabetes_df = diabetes_df.drop(columns = ['Gender','ID', 'No_Pation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7235463b-8c2b-41ae-9075-94a977cbfd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking remaining features after dropping irrelevant columns\n",
    "print(diabetes_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bd71bb-a5f7-4e96-9e61-a66bad8a8082",
   "metadata": {},
   "source": [
    "Preprocessing 1 : outlier handling, filtering, feature capping, encoding and correlation analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff42ff2b-70d7-4acb-9617-bd7a1185511f",
   "metadata": {},
   "source": [
    "IQR Method for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e7270a-f4f8-4eb3-88c7-e093b5b26209",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# handling outliers using the IQR method\n",
    "for col in ['Urea', 'Cr', 'HbA1c', 'Chol', 'TG', 'HDL', 'LDL', 'VLDL', 'BMI']:\n",
    "    q1 = diabetes_df[col].quantile(0.25)\n",
    "    q3 = diabetes_df[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "\n",
    "    #identifying outliers\n",
    "    outliers = diabetes_df[(diabetes_df[col] < lower) | (diabetes_df[col] > upper)] \n",
    "\n",
    "    # printing number of outliers detected for each column\n",
    "    if not outliers.empty:\n",
    "       print(f'{col}: {len(outliers)} outliers')\n",
    "       print('Head:\\n', outliers[[col]].sort_values(by=col).head(10))  \n",
    "       print('Tail:\\n', outliers[[col]].sort_values(by=col).tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bf81b4-4529-4fc4-a5aa-531c84e37bc5",
   "metadata": {},
   "source": [
    "Filtering rows to remove extreme values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95764fc-a54c-46cb-92aa-4c32f9bfa524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering/removing medically unrealistic values based on researched clinical thresholds\n",
    "diabetes_df = diabetes_df[\n",
    "    (diabetes_df['Chol'] > 0) &  \n",
    "    (diabetes_df['HbA1c'] >= 1) &  \n",
    "    (diabetes_df['HDL'] >= 0.5)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c37e1e-82ff-474f-ae33-1459ec6d6c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rechecking summary stats after removing extreme values\n",
    "print(diabetes_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be6e940-7f99-4176-8e48-de1a9f25a1c4",
   "metadata": {},
   "source": [
    "Capping the extreme values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3795add4-3461-429d-a528-d463a5319ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# capping extreme values using medically informed to reduce outlier impact\n",
    "col_caps = {\n",
    "    'Urea' : (5,30),\n",
    "    'Cr' : (45,200), \n",
    "    'HbA1c' : (None, 16),\n",
    "    'Chol' : (None, 9),\n",
    "    'TG' : (None, 10), \n",
    "    'HDL' : (None, 4), \n",
    "    'LDL' : (None, 7), \n",
    "    'VLDL' : (None, 10), \n",
    "    'BMI' : (None, 45)\n",
    "}\n",
    "\n",
    "#  # apply clipping to capped values\n",
    "for col, (lower, upper) in col_caps.items():\n",
    "    diabetes_df[col] = diabetes_df[col].clip(lower=lower, upper=upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7ac9af-c6a7-417a-9588-7c7d95c438f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting class labels from strings to binary integers 0 and 1\n",
    "diabetes_df['CLASS'] = diabetes_df['CLASS'].replace({'N': 0 , 'Y': 1}).astype(int)\n",
    "\n",
    "# confirming successful encoding of class\n",
    "print(diabetes_df['CLASS'].unique()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb27cb3f-bccb-4e1a-a176-32b0ee0e2eaa",
   "metadata": {},
   "source": [
    "Plotting the correlations as a Heatmap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc1892c-b984-40a2-89b7-fcd3069a8797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating feature correlations to detect multicollinearity\n",
    "diabetes_corr = diabetes_df.corr()\n",
    "\n",
    "# visualising correlation matrix as a heatmap\n",
    "sns.heatmap(diabetes_corr, annot=True, fmt='.2f')\n",
    "plt.title('Feature Correlations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7e4e2e-a072-4270-9510-d470a32feded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping BMI for multicollinearity\n",
    "diabetes_df = diabetes_df.drop(columns=['BMI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41028ed8-1090-428f-89d4-4bd849657651",
   "metadata": {},
   "source": [
    "Preprocessing 2: encoding, stratified train-test split, smote and feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a629770-2d13-4562-b3f1-259ff4e1e662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining feature variables X and target variable y\n",
    "X = diabetes_df.drop(columns=['CLASS'])\n",
    "y = diabetes_df['CLASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a39544-0caf-4d86-93e8-d1f25013a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data using stratified shuffle split to maintain class balance in train and test sets\n",
    "strat_split = StratifiedShuffleSplit(n_splits=1, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c415e0-9301-450b-a792-9593e8273ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train and test sets using the split indices\n",
    "for train_index, test_index in strat_split.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "print('Train class distribution:\\n', y_train.value_counts())\n",
    "print('Test class distribution:\\n', y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82787dc7-cade-46b4-9e1c-2fb73580de97",
   "metadata": {},
   "source": [
    "Applying SMOTE to balance class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f29253-bcd5-42c2-850e-e1e5b81a782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying smote to balance the class distribution in the training set\n",
    "smote_sample = SMOTE(random_state=42)\n",
    "X_train_bal, y_train_bal = smote_sample.fit_resample(X_train, y_train)\n",
    "\n",
    "# confirming class balance after SMOTE and verifying test set remains unchanged\n",
    "print('After SMOTE (y_train_bal distribution):\\n', y_train_bal.value_counts())\n",
    "print('Test class distribution:\\n', y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe62847-a001-4c18-89c7-f910aa3d0c5b",
   "metadata": {},
   "source": [
    "Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a0e7f0-f18a-4f83-8538-5c9dc0d30a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling feature values to standardise the data for model training\n",
    "std_scaler = StandardScaler()\n",
    "X_train_scaled = std_scaler.fit_transform(X_train_bal)\n",
    "X_test_scaled = std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e957b2ba-7ad8-4d01-8dca-4423607089bb",
   "metadata": {},
   "source": [
    "Training models - Logistic Regression, KNN, SVC, Naive Bayes & XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bde9f9-b2f9-4948-b0d0-2ddb6dcfb53b",
   "metadata": {},
   "source": [
    "--- Logistic Regression ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763a3bc1-af9b-4919-84c1-8d934ed159ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising the logistic regression model and setting regularisation parameter C to 0.01\n",
    "log_reg = LogisticRegression(class_weight='balanced', C=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2710079a-8c46-46a2-b29a-4916aa0acee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the logistic reg model to the scaled training data\n",
    "log_reg.fit(X_train_scaled, y_train_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5e0a86-229a-4274-8e3d-b257ca1caa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting using the trained logistic regression model with scaled test data\n",
    "y_predict = log_reg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fde2c46-d2ca-4d41-acf4-0874d92e9921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating the logistic regression model performance on the test set\n",
    "train_acc_log = log_reg.score(X_train_scaled, y_train_bal)\n",
    "test_acc_log = log_reg.score(X_test_scaled, y_test)\n",
    "\n",
    "# print accuracies\n",
    "print(f'Train Accuracy: {train_acc_log:.2f}')\n",
    "print(f'Test Accuracy: {test_acc_log:.2f}')\n",
    "\n",
    "# print the classification report for precision, recall, and F1 score\n",
    "print('Logistic Regression Classification Report\\n',classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ab15fe-0329-466a-918b-923802361d13",
   "metadata": {},
   "source": [
    "Logistic Regression Confusion Matrix Visualised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202bc672-3d96-42c5-930d-e8010e3039cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the confusion matrix for Logistic Regression\n",
    "log_reg_cm = confusion_matrix(y_test, y_predict) \n",
    "\n",
    "# plotting confusion matrix for visual interpretation of misclassifications\n",
    "plt.figure()\n",
    "sns.heatmap(log_reg_cm, annot=True, fmt='d', cmap='Greens', xticklabels=['Non-Diabetic', 'Diabetic'], yticklabels=['Non-Diabetic', 'Diabetic'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Logistic Regression Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60584cd1-9c39-45ab-bc5c-2040561d52fb",
   "metadata": {},
   "source": [
    "--- KNN- --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c83fa2-9b79-4757-b19b-d9050214b3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising the KNN model with 5 neighbors default value for simplicity\n",
    "k_nearest = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eef363-0849-4857-9790-fc8eb8e2223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the KNN model to the scaled training data\n",
    "k_nearest.fit(X_train_scaled, y_train_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb5a6c4-ad47-4cac-85b1-832ad6d41379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting using the trained KNN model with scaled test data\n",
    "y_predict_knn = k_nearest.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d9dd57-04ce-437f-a99c-c107ae16d5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating KNN model performance on the test set\n",
    "train_acc_knn = k_nearest.score(X_train_scaled, y_train_bal)\n",
    "test_acc_knn = k_nearest.score(X_test_scaled, y_test)\n",
    "\n",
    "# print accuracies\n",
    "print(f'Train Accuracy: {train_acc_knn:.2f}')\n",
    "print(f'Test Accuracy: {test_acc_knn:.2f}')\n",
    "\n",
    "# print the classification report for precision, recall, and F1 score\n",
    "print('KNN Classification Report\\n', classification_report(y_test, y_predict_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c9bede-2d85-4054-bfab-c33cbfbb5cb2",
   "metadata": {},
   "source": [
    "KNN Confusion Matrix Visualised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48529b64-4af5-4861-81a5-06b14441425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the confusion matrix for KNN\n",
    "knn_cm = confusion_matrix(y_test, y_predict_knn)\n",
    "\n",
    "# print the confusion matrix to see true/false positives and negatives\n",
    "plt.figure()\n",
    "sns.heatmap(knn_cm, annot=True, fmt='d', cmap='Greens', xticklabels=['Non-Diabetic', 'Diabetic'], yticklabels=['Non-Diabetic', 'Diabetic'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('KNN Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432067ff-afbf-4f08-ae88-c90b05520090",
   "metadata": {},
   "source": [
    "Visualising best Ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbb4126-25ac-4568-90c6-6a6b42fcec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists to store accuracy and corresponding k values\n",
    "acc = []\n",
    "md = []\n",
    "\n",
    "# iterating over k values from 1 to 20\n",
    "for i in range(1, 21):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i) # initialise KNN model with current k\n",
    "    knn.fit(X_train_scaled, y_train_bal)  # Train on balanced & scaled data\n",
    "    acc.append(knn.score(X_test_scaled, y_test))  # test accuracy\n",
    "    md.append(i)\n",
    "\n",
    "# plotting KNN accuracy for different k values\n",
    "plt.figure()\n",
    "plt.plot(md, acc, label='KNN', marker='o', linestyle='-')\n",
    "plt.xlabel('n_neighbors (k)')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.title('KNN Accuracy vs. K-Value on Diabetes Data')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7d7fd0-2aac-4837-a2a6-29b9c000900c",
   "metadata": {},
   "source": [
    "--- SVC ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529a3aea-3142-4d59-9d79-d9ac02f14439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising the SVC model with default parameters\n",
    "svc_rbf = SVC(kernel='rbf', C=1, gamma='scale', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1608e2b-e1f7-4bd6-aef2-8d215032bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the SVC model on scaled training data\n",
    "svc_rbf.fit(X_train_scaled, y_train_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac588ed-9498-4349-ab51-dd51b5cad5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting with the SVC model using the scaled test data\n",
    "svc_y_predict = svc_rbf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63212b4d-931f-493f-80ff-f8592b5b5edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating train and test accuracy for SVC model\n",
    "svc_trACC = svc_rbf.score(X_train_scaled, y_train_bal)\n",
    "svc_tesACC = svc_rbf.score(X_test_scaled, y_test)\n",
    "\n",
    "# print accuracies\n",
    "print(f'Train Accuracy: {svc_trACC:.2f}')\n",
    "print(f'Test Accuracy: {svc_tesACC:.2f}')\n",
    "\n",
    "\n",
    "# print the classification report\n",
    "print('SVC Classification Report\\n', classification_report(y_test, svc_y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e023cc-4833-4cb6-ab86-67ee816cc7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the confusion matrix for SVC\n",
    "svc_cm = confusion_matrix(y_test, svc_y_predict)\n",
    "\n",
    "# plotting confusion matrix for visual interpretation of misclassifications\n",
    "plt.figure()\n",
    "sns.heatmap(svc_cm, annot=True, fmt='d', cmap='Greens', xticklabels=['Non-Diabetic', 'Diabetic'], yticklabels=['Non-Diabetic', 'Diabetic'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('SVC Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdc7a54-f071-4d1b-a36c-4e53e3019323",
   "metadata": {},
   "source": [
    "--- Na√Øve Bayes ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e684a7f2-3ca9-4179-96f3-eed114d314e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising the Naive Bayes model\n",
    "nb_gaussian = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e5df55-76c9-4d75-8942-7d517f58abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the Naive Bayes model on scaled training data\n",
    "nb_gaussian.fit(X_train_scaled, y_train_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b380738-b390-436b-a65a-89da9a91c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting with the Naive Bayes model using the scaled test data\n",
    "nb_y_predict = nb_gaussian.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ad3045-9cbd-4f07-a3e2-3f6ee31a77f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating train and test accuracy for Naive Bayes model\n",
    "nb_trACC = nb_gaussian.score(X_train_scaled, y_train_bal)\n",
    "nb_tesACC = nb_gaussian.score(X_test_scaled, y_test)\n",
    "\n",
    "# print accuracies\n",
    "print(f'Train Accuracy: {nb_trACC:.2f}')\n",
    "print(f'Test Accuracy: {nb_tesACC:.2f}')\n",
    "\n",
    "# print the classification report\n",
    "print('Naive Bayes Classification Report\\n',classification_report(y_test, nb_y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a40b1-d489-41a1-a832-eab47b3a3247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the confusion matrix for Naive Bayes\n",
    "nb_cm = confusion_matrix(y_test, nb_y_predict)\n",
    "\n",
    "# plotting confusion matrix for visual interpretation of misclassifications\n",
    "plt.figure()\n",
    "sns.heatmap(nb_cm, annot=True, fmt='d', cmap='Greens', xticklabels=['Non-Diabetic', 'Diabetic'], yticklabels=['Non-Diabetic', 'Diabetic'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Naive Bayes Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b883efb7-a538-41dc-b13d-abe85a30f963",
   "metadata": {},
   "source": [
    "--- XGBoost ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc8169f-95f3-4550-8816-d570bcce4ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising the XGBoost model with default parameters\n",
    "xgbst = XGBClassifier(objective = 'binary:logistic', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad1a2eb-7581-43f8-a5f9-3588604cfece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the XGBoost model on scaled training data\n",
    "xgbst.fit(X_train_scaled, y_train_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b330c8-c459-4fd3-a5a5-3899b070733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting with the XGBoost model using the scaled test data\n",
    "xgbst_y_predict = xgbst.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470d5029-6acd-476a-baa0-a418c6b92efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating train and test accuracy for XGBoost model\n",
    "xgb_trACC = xgbst.score(X_train_scaled, y_train_bal)\n",
    "xgb_tesACC = xgbst.score(X_test_scaled, y_test)\n",
    "\n",
    "# print accuracies\n",
    "print(f'Train Accuracy: {xgb_trACC:.2f}')\n",
    "print(f'Test Accuracy: {xgb_tesACC:.2f}')\n",
    "\n",
    "# print the classification report\n",
    "print('XGBoost Classification Report:\\n',classification_report(y_test, xgbst_y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d60dc3a-ad25-4884-aa54-5a80cdab7a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the confusion matrix for XGBoost\n",
    "xgbst_cm = confusion_matrix(y_test, xgbst_y_predict)\n",
    "\n",
    "# plotting confusion matrix for visual interpretation of misclassifications\n",
    "plt.figure()\n",
    "sns.heatmap(xgbst_cm, annot=True, fmt='d', cmap='Greens', xticklabels=['Non-Diabetic', 'Diabetic'], yticklabels=['Non-Diabetic', 'Diabetic'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('XGBoost Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb039495-ba98-42dc-8ad2-58f2ae123227",
   "metadata": {},
   "source": [
    "Hyperperameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0fafbd-b955-4971-9f5d-635477b190b8",
   "metadata": {},
   "source": [
    "--- KNN Tuning---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dccdf23-7b18-4279-b3c2-4fc99adf4789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameter grid for KNN - range of k values\n",
    "param_knn = {'n_neighbors' : list(range(2,21))}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86310de1-1b85-4b2e-8d6c-1da9ffbf7e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing grid search with 5-fold cross-validation for KNN\n",
    "k_nearest_gs = GridSearchCV(knn, param_knn, cv=5, scoring='f1', n_jobs=-1, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b2f3a4-95cb-4f63-859f-ee1d06ea143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the grid search model on scaled training data\n",
    "k_nearest_gs.fit(X_train_scaled, y_train_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570fcb7d-0f97-4d41-8b60-7f4b74496462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving the best k value from grid search\n",
    "best_k_tuned = k_nearest_gs.best_params_['n_neighbors']\n",
    "print(f'Best K Value: {best_k_tuned}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2598cab-9238-49a9-918d-5c2d51b4fba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the best KNN model from grid search\n",
    "best_knn = k_nearest_gs.best_estimator_\n",
    "print(f'Best Tuned KNN F1 score on Train Data: {k_nearest_gs.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f92265-9741-4064-a1d6-b55166c4c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting with the best KNN model using the scaled test data\n",
    "knn_tuned_y_predict = best_knn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afaf9d2-e62e-4bfc-9bc3-07cee484e3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating train and test accuracy for tuned KNN model\n",
    "knn_gs_trACC = best_knn.score(X_train_scaled, y_train_bal)\n",
    "knn_gs_tesACC = best_knn.score(X_test_scaled, y_test)\n",
    "\n",
    "# print accuracies\n",
    "print(f'Train Accuracy: {knn_gs_trACC:.2f}')\n",
    "print(f'Test Accuracy: {knn_gs_tesACC:.2f}')\n",
    "\n",
    "# Tuned Classification Report\n",
    "print('Tuned KNN Classification Report\\n', classification_report(y_test, knn_tuned_y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecf780e-a447-4928-8989-b8f39df38d60",
   "metadata": {},
   "source": [
    "KNN Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c7bc4a-7ce4-48f5-bd67-203b2c0ef154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting cross-validation results into a dataframe\n",
    "results = pd.DataFrame(k_nearest_gs.cv_results_)\n",
    "\n",
    "# gettting k values and corresponding mean train and test scores\n",
    "k_values = results['param_n_neighbors']\n",
    "train_scores = results['mean_train_score']\n",
    "test_scores = results['mean_test_score']\n",
    "\n",
    "# plot the validation curve for knn\n",
    "plt.plot(k_values, train_scores, label='train', marker='o')\n",
    "plt.plot(k_values, test_scores, label='test', marker='o')\n",
    "plt.xlabel('number of neighbors (k)')\n",
    "plt.ylabel('f1 score')\n",
    "plt.title('validation curve for knn')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93744941-06e0-4cb8-b011-fa9a55ead830",
   "metadata": {},
   "source": [
    "Hypermater Tuning SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155f827b-534f-4281-9c56-3e7aa74fba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameter grid for SVC - testing different C, gamma and kernel values\n",
    "param_svc = {'C': [0.1, 1, 10],\n",
    "                  'gamma': [0.001, 0.01, 0.1, 1, 'scale'],\n",
    "                  'kernel': ['rbf', 'poly', 'sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca2aa8-002b-4881-94e6-c301c0691206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing grid search with 5-fold cross-validation for SVC\n",
    "svc_gs = GridSearchCV(SVC(class_weight='balanced'), param_svc, cv=5, scoring='f1', n_jobs=-1, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b701060-54d9-4c1a-982e-c7cd98d16b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the grid search model on scaled training data\n",
    "svc_gs.fit(X_train_scaled, y_train_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11b1ce5-626e-4736-b993-f3534512f727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving the best parameters from grid search\n",
    "svc_best_param = svc_gs.best_params_\n",
    "print(f'Best SVC Parameters: {svc_best_param}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1fe05e-549a-41c5-a6ea-fed04aabe441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the best SVC model from grid search\n",
    "svc_best_model = svc_gs.best_estimator_\n",
    "print(f'Best SVC F1 score: {svc_best_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af93d3d3-7218-4df7-b836-d4fbf4b8b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting with the best SVC model using the scaled test data\n",
    "svc_tuned_y_predict = svc_best_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13076d6e-ae76-4e6f-a242-85c98f12a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating train and test accuracy for tuned SVC model\n",
    "svc_gs_trACC = svc_best_model.score(X_train_scaled, y_train_bal)\n",
    "svc_gs_tesACC = svc_best_model.score(X_test_scaled, y_test)\n",
    "\n",
    "# print accuracies\n",
    "print(f'Train Accuracy: {svc_gs_trACC:.2f}')\n",
    "print(f'Test Accuracy: {svc_gs_tesACC:.2f}')\n",
    "\n",
    "print('Tuned SVC Classification Report\\n', classification_report(y_test, svc_tuned_y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b72206-7b7d-497f-b79e-71abd53d1d61",
   "metadata": {},
   "source": [
    "SVC Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073297c2-41f4-41eb-8638-86335322b610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract grid search results into a dataframe\n",
    "results_svc = pd.DataFrame(svc_gs.cv_results_)\n",
    "\n",
    "# get C values and mean test scores\n",
    "c_values = results_svc['param_C']\n",
    "test_scores = results_svc['mean_test_score']\n",
    "\n",
    "# plot validation curve for svc\n",
    "plt.figure()\n",
    "plt.plot(c_values, test_scores, marker='o')\n",
    "plt.xlabel('C value')\n",
    "plt.ylabel('f1 score')\n",
    "plt.title('validation curve for svc')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f31d833-cf64-412d-9036-a922be1893c2",
   "metadata": {},
   "source": [
    "Hyperameter Tuning XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d145a9d-004d-44d5-b304-0fd7d5f3bfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameter grid for XGBoost to tune tree depth, learning rate and subsampling\n",
    "param_xgboost = {'n_estimators': [50, 100],\n",
    "                  'max_depth': [3, 5, 7],\n",
    "                  'learning_rate': [0.01, 0.1],\n",
    "                  'subsample': [0.8, 1.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b7b037-db57-43c1-8a9f-a8f1f4fbca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing grid search with 5-fold cross-validation for XGBoost\n",
    "xgboost_gs = GridSearchCV(XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "                               param_xgboost, cv=5, scoring='f1', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a68534-8973-4bb0-9611-68b936fffa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the grid search model on scaled training data\n",
    "xgboost_gs.fit(X_train_scaled, y_train_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cda78b3-e6a5-4042-889f-e9e7065c16be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving the best parameters from grid search\n",
    "xgboost_best_param = xgboost_gs.best_params_\n",
    "print(f'Best XGBoost Parameters:\\n {xgboost_best_param}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc3195e-514f-4662-b7e7-9c61eb131a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the best XGBoost model from grid search\n",
    "xgboost_best_model = xgboost_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bafbf6-38cc-468f-9457-63577b633fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting with the best XGBoost model using the scaled test data\n",
    "xgboost_tuned_y_predict = xgboost_best_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf55215-edd4-4f12-b825-1deb557fda00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating train and test accuracy for tuned XGBoost model\n",
    "xgb_gs_trACC = xgboost_best_model.score(X_train_scaled, y_train_bal)\n",
    "xgb_gs_tesACC = xgboost_best_model.score(X_test_scaled, y_test)\n",
    "\n",
    "# print accuracies\n",
    "print(f'Train Accuracy: {xgb_gs_trACC:.2f}')\n",
    "print(f'Test Accuracy: {xgb_gs_tesACC:.2f}')\n",
    "\n",
    "# print the classification report\n",
    "print('Tuned XGBoost Classification Report:\\n', classification_report(y_test, xgboost_tuned_y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b36953-ae5d-48d2-b3ee-224874e71542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the confusion matrix for tuned XGBoost\n",
    "xgboost_gs_cm = confusion_matrix(y_test, xgboost_tuned_y_predict)\n",
    "\n",
    "# plotting confusion matrix for visual interpretation of misclassifications\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(xgboost_gs_cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Diabetic', 'Diabetic'], yticklabels=['Non-Diabetic', 'Diabetic'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Tuned XGBoost Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d092459f-57a0-490a-a0cf-04b96d052bb3",
   "metadata": {},
   "source": [
    "F1 Score Barplot for all Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb057c33-7923-4002-9d07-4415cb286c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 scores for each tuned model based on final outputs\n",
    "f1_scores = [0.86, 0.88, 0.86, 0.84, 0.90]\n",
    "model_names = ['Logistic Regression', 'KNN', 'SVC', 'Naive Bayes', 'XGBoost']\n",
    "\n",
    "# create bar plot for f1 scores\n",
    "plt.figure()\n",
    "plt.bar(model_names, f1_scores)\n",
    "plt.xlabel('model')\n",
    "plt.ylabel('f1 score')\n",
    "plt.title('f1 scores of tuned models')\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b9e012-547d-43fd-95f1-56b675dddc72",
   "metadata": {},
   "source": [
    "Comparing Models ROC and AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a46ca-99a3-436c-a812-c32fdf9a68a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting predicted probabilities or decision scores for ROC curve\n",
    "log_reg_probs = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "knn_probs = best_knn.predict_proba(X_test_scaled)[:, 1] \n",
    "svc_probs = svc_best_model.decision_function(X_test_scaled)\n",
    "nb_probs = nb_gaussian.predict_proba(X_test_scaled)[:, 1]\n",
    "xgboost_probs = xgboost_best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# storing model names and their probabilities/scores\n",
    "models = {\n",
    "    'Logistic Regression': log_reg_probs,\n",
    "    'KNN': knn_probs,\n",
    "    'SVC': svc_probs,\n",
    "    'Naive Bayes': nb_probs,\n",
    "    'XGBoost': xgboost_probs}\n",
    "\n",
    "# plotting ROC curves for each model\n",
    "plt.figure()\n",
    "for name, probs in models.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc_score:.2f})')\n",
    "\n",
    "# plotting baseline random classifier\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Classifier')\n",
    "\n",
    "# formatting plot\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1874128-e127-4fb3-a80a-0b02ac94589e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
